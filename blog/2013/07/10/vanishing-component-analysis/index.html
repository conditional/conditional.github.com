
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>どんなデータでも(※)線形分離可能にしてしまう技術，Vanishing Component Analysis(ICML 2013)を紹介してきました - a lonely miner</title>
  <meta name="author" content="Koji Matsuda">

  
  <meta name="description" content="急に蒸し暑くなってきましたね．でぶちんなのでけっこうこたえます．タイトルはちょっと釣り気味．ビビっと来た方は是非論文に目を通してみてください:) 例によって，仲間内でやっている小さな勉強会で論文紹介をしてきましたので，そのご紹介です．ぼくの専門というか興味の中心は自然言語処理なので， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://conditional.github.io/blog/2013/07/10/vanishing-component-analysis">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="a lonely miner" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39246182-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">a lonely miner</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:conditional.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">どんなデータでも(※)線形分離可能にしてしまう技術，Vanishing Component Analysis(ICML 2013)を紹介してきました</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-07-10T11:30:00+09:00" pubdate data-updated="true">Jul 10<span>th</span>, 2013</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>急に蒸し暑くなってきましたね．でぶちんなのでけっこうこたえます．タイトルはちょっと釣り気味．ビビっと来た方は是非論文に目を通してみてください:)</p>

<p>例によって，仲間内でやっている小さな勉強会で論文紹介をしてきましたので，そのご紹介です．ぼくの専門というか興味の中心は自然言語処理なので，ふだんはそっち方面を追っているのですが，勉強会では機械学習方面を中心にいろいろ読んでみてます．</p>

<p>今回は岡野原さんのこのツイートで興味を持った以下の論文を読ませていただきました．名前もかっこいい．<strong>ヴァニッシングコンポーネントアナリシス！</strong></p>

<blockquote class="twitter-tweet"><p>ICML2013のbestpaper。データ中の集合（例えば画像中の8の字など）が0になるような生成多項式を求める（=集合のコンパクトな表現）効率的なアルゴリズムを提案し教師有学習時の特徴生成などに使える。すごい <a href="http://t.co/DedSoyLaJR">http://t.co/DedSoyLaJR</a></p>&mdash; 岡野原 大輔 (@hillbig) <a href="https://twitter.com/hillbig/statuses/347504853205000193">June 20, 2013</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<ul>
<li><a href="http://jmlr.org/proceedings/papers/v28/livni13.pdf">&#8220;Vanishing Component Analysis&#8221;</a> Roi Livni et al, ICML 2013 (Best Paper)</li>
</ul>


<iframe src="http://www.slideshare.net/slideshow/embed_code/24079705" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://www.slideshare.net/koji_matsuda/vanishing-component-analysis" title="Vanishing Component Analysis" target="_blank">Vanishing Component Analysis</a> </strong> from <strong><a href="http://www.slideshare.net/koji_matsuda" target="_blank">koji_matsuda</a></strong> </div></p>

<p>タイミングよく，<a href="http://partake.in/events/0ae21389-aa2a-42c1-a247-f93582127216">ICML2013読み会</a>という企画に乗っかるチャンスを頂けたので，今回はそちらでもお話させていただきました．会場には40人ほどいらっしゃったでしょうか．思いのほか多くの方が集まっており，演台から会場をみたときにちょっと圧倒されちゃいました・・・．外部でお話するのはとても久しぶりだったのですが，たいへん楽しい会でした．主催の <a href="http://twitter.com/sla">@sla</a> さん，会場を提供してくださった中川先生，ありがとうございました．</p>

<p>この論文は，PCAやICAに代表される<strong>Component Analysis</strong>に，これまでとはまったく別の角度からアタックした論文です．</p>

<p>PCA,ICAというと，特徴量抽出とか信号分離などによく使われているイメージですね．多くの「なんとかComponent Analysis」はデータの成分がある種の確率分布(多くの場合，正規分布)にしたがって生成されているという仮定に立脚しています．また，見つけることのできる成分（基底といいます）は線形なものに限られることがほとんど．</p>

<p>対してこの論文では，<strong>「多項式」で表現されるような基底を抜き出す</strong>ことに焦点を当てています．無理やり1ページで説明しようとするとこんな感じ．</p>

<p><img class="center" src="/images/VCA.png" width="650"></p>

<p>で，興味をもっていただけましたらスライドを眺めていただきたいのですが，この「多項式集合」を特徴量抽出に使うと，いい感じに<strong>組み合わせを考慮した素性を抽出</strong>することができるようです．しかも，（※多少の前提条件は必要ですが）この方法で抽出した特徴ベクトルを分類問題に適用すると，<strong>線形分離できることが保証される</strong>，というありがたさ．多項式カーネルを直接用いる分類に比べ，精度がほとんど落ちることなく，分類において最大100倍ほどの高速化を達成しています．</p>

<p>今後もいろいろな展開が考えられる，読んでいて楽しい論文でした．手法や達成した性能自体が凄い，というよりは，これまで機械学習で殆ど用いられてこなかった<strong>代数幾何の概念を完成度の高い形で既存の問題設定に組み込んだ</strong>．というのがBest Paperとして評価された一因なのかなとも思います．</p>

<p>ICML読み会での発表後にTwitterを眺めていたら，</p>

<blockquote class="twitter-tweet"><p>さっきグレブナー基底とか何とか言ったけど、これはむしろ自由度の高い単なる多項式回帰な気がするので、今からちゃんと読むです… [要出典]</p>&mdash; ぽよ子 (@tara_nai) <a href="https://twitter.com/tara_nai/statuses/354593532855590912">July 9, 2013</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>とのご指摘が・・・．これはすずかけ台の勉強会でも指摘されて，ちょっとアレレってなっていた部分でもありました．説明できなくてスミマセン．</p>

<p>未だにアレレってなっているのですが，たしかに問題自体は多項式回帰の枠組みで考えることもできそうです．ただ，効率的にかつ冗長性を抑えながら，できるだけ小さい次数からFilterしていくということを考えると，イデアルのもつ吸収律を活用する，VCAのような枠組みが有効に働いてくるのではないかと思います．（スミマセン，イデアルとはいったい何なのか，グレブナー基底とはいったい何なのか，未だにあんまりわかってないので自信はありません・・・）</p>

<p>ちなみにこのチーム，すでに<strong>Deep Learningへの応用</strong>を考えていらっしゃるみたいで，そちらの<a href="http://arxiv.org/abs/1304.7045">プレプリント</a>も出てたりします．なんともはや．</p>

<p>他の方の発表も興味深い話が盛りだくさんで，すずかけの方では元同期の <a href="http://twitter.com/tma15">@tma15</a> くんが<a href="http://tma15.github.io/blog/2013/7/it-takes-a-long-time-to-become-young.html">オンラインコミュニティにおける参加者の寿命を言語的特徴から推測する話(WWWのベストペーパー)</a>を紹介してくれたり，ICML読み会のほうは．</p>

<ul>
<li>超多クラスのロジスティック回帰の分散学習</li>
<li>オンラインのマルチタスク学習(Lifelong Learningというらしいです)の爆速化</li>
<li>重みベクトルのビット数をAdaptiveに調節して省メモリに</li>
<li>ローカルには線形なSVMを多数組み合わせることで非線形分類を高速化</li>
<li>Deep LearningにおけるRectifierに代わる活性化関数Maxoutの提案</li>
<li>高次の共起を考慮にいれたタグの補完に基づいた高速画像タギング</li>
<li>ビデオ映像からの人間の動作認識</li>
<li>複数の目的関数をパレート最適に持っていくようなActive Learning</li>
<li>あんまり確率的ではないTopic Modelとその特徴付け</li>
</ul>


<p>などなど（発表の要旨をつかめてなかったらすみません），何でもありな感じでワクテカ．実際の現場で機械学習を応用されてるPFIの方の発表が多かったこともあり，<strong>精度を下げずにいかに高速化するか</strong>，という方向性の論文が多かったように思います．</p>

<p>個人的には， @sla さんがオープニングで話してくださった，「<strong>なんでもi.i.dを仮定するのはそろそろ脱却して，時間/空間に沿って変化するような動的なデータに対しても理論を作っていくべき</strong>」というコメントがたいへん興味深く感じました．</p>

<p>機械学習が実世界に浸透していくにしたがって，これからはひとつのモデルなり分類器なりがそれなりに長く使われることを考えなければならない時期にきているのかなとも思います．そういう状況のもとでは，(たとえば言語の話でいえばその時々で流行語があるように)<strong>入力の分布がどんどん変わっていく</strong>ような状況に対してうまく適応していくような問題設定を明確に意識していく必要がありそうです．
<a href="http://twitter.com/unnonouno">@unnonouno</a> さんが紹介してくださった，Lifelong Learningも，そういうモチベーションを含んでいるのかな．</p>

<p>私個人としましては，もう長いこと途絶えてしまっている外部へのアウトプットを再開するよい機会になりましたので，今後は知識を頂くだけではなく，自分の学んだことを共有することを心がけていきたいと感じた会でした．</p>

<p>久しぶりにお会いした方もいらっしゃったので，ゆっくりお話できれば良かったのですが，ちょっと事情がありまして早々と帰宅．また近いうちにお会いできる機会があれば幸いです（人生相談にのっていただきたいのでした・・・）</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Koji Matsuda</span></span>

      








  


<time datetime="2013-07-10T11:30:00+09:00" pubdate data-updated="true">Jul 10<span>th</span>, 2013</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/learning/'>learning</a>, <a class='category' href='/blog/categories/machine/'>machine</a>
  
</span>


    </p>
    
      <div class="sharing">
  <a href="http://b.hatena.ne.jp/entry/http://conditional.github.io/blog/2013/07/10/vanishing-component-analysis/" class="hatena-bookmark-button" data-hatena-bookmark-layout="standard" title="このエントリーをはてなブックマークに追加"><img src="http://b.st-hatena.com/images/entry-button/button-only.gif" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="http://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://conditional.github.io/blog/2013/07/10/vanishing-component-analysis/" data-via="conditional" data-counturl="http://conditional.github.io/blog/2013/07/10/vanishing-component-analysis/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/06/01/machine-learning-framework-for-programming-by-example/" title="Previous Post: Programming by Exampleに対する機械学習からのアプローチ（あるいは，「重い」処理を機械学習で「軽く」する，という視点）について">&laquo; Programming by Exampleに対する機械学習からのアプローチ（あるいは，「重い」処理を機械学習で「軽く」する，という視点）について</a>
      
      
        <a class="basic-alignment right" href="/blog/2013/08/03/joint-modeling-of-a-matrix-with-associated-text-via-latent-binary-features/" title="Next Post: コンピュータが政治をする時代(あるいは，行列とテキストの結合モデル)について">コンピュータが政治をする時代(あるいは，行列とテキストの結合モデル)について &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>ロンリーなマイナーです．</p>
  <ol>
  <li><a href="http://twitter.com/conditional">Twitter</a></li>
  </ol>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/01/13/report-of-dsirnlp5/">「モデル」とは何か，について考えていたことを，DSIRNLP(データ構造と情報検索と言語処理勉強会)で発表してきました</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/07/an-introduction-to-torch7/">[MLAC 2013 7日目] Torch7でお手軽ニューラルネットワーク</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/22/practical-recommendations-for-gradient-based-training-of-deep-architectures/">Deep Learning : Bengio先生のおすすめレシピ</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/08/report-of-snlp5/">第5回 最先端NLP勉強会に参加してきました</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/08/19/acl2013-reading-list-part-1/">ACL2013 マイ・リーディングリスト(1)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/08/03/joint-modeling-of-a-matrix-with-associated-text-via-latent-binary-features/">コンピュータが政治をする時代(あるいは，行列とテキストの結合モデル)について</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/07/10/vanishing-component-analysis/">どんなデータでも(※)線形分離可能にしてしまう技術，Vanishing Component Analysis(ICML 2013)を紹介してきました</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/01/machine-learning-framework-for-programming-by-example/">Programming by Exampleに対する機械学習からのアプローチ（あるいは，「重い」処理を機械学習で「軽く」する，という視点）について</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/06/predicting-google-closures/">統計データに基づくGoogle各種サービスの生存予測</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/05/predicting-google-closures/">Predicting Google Closures</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/20/distance-metric-learning-and-kernel-learning/">距離計量学習とカーネル学習について</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/01/unsupervised-wsd-with-graph-connectivity/">グラフ結合度に基づく教師なし語義曖昧性解消について</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/03/23/about-posterior-regularization-and-unified-expectation-maximization/">Posterior Regularization と Unified Expectation Maximizationについて</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/03/14/take-a-nap-with-prowl/">Prowl+zshで快適お昼寝タイム</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/03/13/start-bloging-with-octopress/">Start Bloging With Octopress</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Koji Matsuda -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'condi';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://conditional.github.io/blog/2013/07/10/vanishing-component-analysis/';
        var disqus_url = 'http://conditional.github.io/blog/2013/07/10/vanishing-component-analysis/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
